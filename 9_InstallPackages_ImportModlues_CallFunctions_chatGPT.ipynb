{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lje5149/NLP_2023/blob/main/9_InstallPackages_ImportModlues_CallFunctions_chatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ Python Library\n",
        "  - Python modues ì„ ê³„ì¸µì ì¸ ë””ë ‰í† ë¦¬ í˜•íƒœë¡œ êµ¬ì„±\n",
        "  - **!pip**: Package manager\n",
        "  - **!pip install <font color = 'red'> NameLibrary**\n",
        "> A <font color = 'red'> **Python library**</font> refers to a collection of modules or functions that provide specific functionality, often focused on a particular domain or purpose. Libraries can be used to extend the capabilities of Python by providing pre-written code that can be imported and used in your own programs. Examples of popular Python libraries include NumPy for numerical computing, pandas for data manipulation and analysis, and requests for making HTTP requests. On the other hand, a <font color = 'blue'> **Python package**</font> is a way of organizing related modules into a directory hierarchy. A package is essentially a directory that contains one or more Python module files, along with an optional __init__.py file that signifies it as a package. Packages help to organize and structure large codebases by grouping related functionality together. They can also contain sub-packages, creating a nested structure.\n",
        "\n",
        "# ğŸ’ğŸ’ Python Moduess\n",
        "  - Python functions ë¡œ êµ¬ì„±\n",
        "  - **from í˜í‚¤ì§€ì´ë¦„ import ëª¨ë“ˆì´ë¦„**\n",
        "  - **import** **í˜í‚¤ì§€.ëª¨ë“ˆì´ë¦„ <font color='green'>[ì™¸ë¶€ í˜í‚¤ì§€ ê²½ìš°]**</font>\n",
        "  - **import ëª¨ë“ˆì´ë¦„ <font color='purple'>[Python ë‚´ì¥ í˜í‚¤ì§€ ê²½ìš°]**</font>\n",
        "  - **import ëª¨ë“ˆì´ë¦„ as Abbreviation**\n",
        "\n",
        "\n",
        "# ğŸ€ âš½ âš¾ ğŸ¾ Python functions\n",
        "  - ì™¸ë¶€ ëª¨ë“ˆì— ìˆëŠ” í•¨ìˆ˜\n",
        "  - import ëª¨ë“ˆì´ë¦„.í•¨ìˆ˜ì´ë¦„()\n",
        "  - from ëª¨ë“ˆì´ë¦„ import í•¨ìˆ˜ì´ë¦„\n",
        "\n",
        "### For you information, check out **Python Module Index**\n",
        "* [Visit Colab documentation]((https://docs.python.org/3/py-modindex.html)\n",
        "\n"
      ],
      "metadata": {
        "id": "aCsaIGXK73ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "ldD78wQ_xSj_",
        "outputId": "30bc56b8-085d-45bb-c0c4-a2cc3169d1e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color = 'purple'> **ğŸ‘€ Install Python Libraries** â¤µï¸"
      ],
      "metadata": {
        "id": "nR3MiBaAM--d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ğŸ¹ ğŸ‘€ ğŸ¾ The **Pandas** is a popular open-source library for data manipulation and analysis. It offers data structures like **Series and DataFrame for handling structured data**. With powerful functionalities, it enables tasks such as <font color = 'red'>**indexing, filtering, grouping, and merging data**</font>. Pandas supports various file formats and integrates well with other libraries like NumPy and Matplotlib. It provides an intuitive and efficient way to work with large datasets in Python.\n",
        "\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "9olyrXb-H-mq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ğŸ¹ ğŸ‘€ ğŸ¾ The **scikit-learn**, often referred to as sklearn, is a widely used **machine learning library**. It provides a comprehensive collection of tools and algorithms for various machine learning tasks such as <font color = 'red'>**classification, regression, clustering, and dimensionality reduction**</font>. With a consistent and user-friendly API, scikit-learn simplifies the process of building machine learning models. It supports data preprocessing, feature selection, model evaluation, and model tuning. The library also offers helpful utilities for handling datasets and implementing machine learning workflows. Overall, scikit-learn is a valuable resource for both beginners and experienced practitioners in the field of machine learning.\n",
        "\n",
        "!pip install scikit-learn #corpus-toolkit íŒ¨í‚¤ì§€ì— í•˜ì´í”ˆ ìˆìŒ"
      ],
      "metadata": {
        "id": "sD-yK0LIICxj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ğŸ¹ ğŸ‘€ ğŸ¾ The **Matplotlib** is a popular plotting library for Python. It provides a flexible and comprehensive set of tools for creating various types of plots and visualizations. With a simple and intuitive interface, Matplotlib allows customization of plot appearance, axes, labels, and styles. It supports <font color = 'red'>**line plots, scatter plots, bar charts, histograms**</font>, and more. Matplotlib *integrates well with NumPy and Pandas for data manipulation and analysis*. It is widely used for data exploration, presentation, and publication-quality visualizations in scientific computing and data analysis.\n",
        "\n",
        "!pip install matplot"
      ],
      "metadata": {
        "id": "Yo1rFBHOIOrA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ğŸ¹ ğŸ‘€ ğŸ¾ The **NLTK** (Natural Language Toolkit) is a powerful library for natural language processing (NLP) tasks. It provides tools and resources for tasks like <font color = 'red'>**tokenization, stemming, tagging, parsing, and sentiment analysis**</font>. NLTK offers a wide range of corpora and lexical resources for linguistic analysis. It supports **text classification, text generation, and language modeling**. NLTK includes pre-trained models and algorithms for various NLP tasks, making it suitable for both beginners and advanced users in the field of NLP. Overall, NLTK is a valuable resource for working with *human language data and performing NLP tasks in Python*.\n",
        "\n",
        "!pip install nltk"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LKUrjZgzza9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ğŸ¹ ğŸ‘€ ğŸ¾ **Corpus-toolkit** package grew out of courses in corpus linguistics and learner corpus research. The toolkit attempts to balance simplicity of use, broad application, and scalability. Common corpus analyses such as <font color = 'red'>**the calculation of word and n-gram frequency and range, keyness, and collocation**</font> are included. In addition, more advanced analyses such as the **identification of dependency bigrams (e.g., verb-direct object combinations) and their frequency, range, and strength of association** are also included.\n",
        "\n",
        "!pip install corpus-toolkit #corpus-toolkit íŒ¨í‚¤ì§€ì— í•˜ì´í”ˆ ìˆìŒ"
      ],
      "metadata": {
        "id": "aFjO_wBAH5Ql",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'brown'> Student's activity** â¤µï¸\n",
        "\n",
        "### Exercise for <font color = 'red'> installing nltk package, importing its module, and calling its functions\n",
        "\n",
        "**NLTK: Python library**\n",
        "* You are correct! When using **Google Colab**, certain libraries, including **NLTK**, are **pre-installed and available for immediate use** without the need for additional installation. This is because Colab provides a pre-configured environment with several popular libraries and modules already installed, allowing you to import and use them directly in your code. So, in the case of using Colab, you can indeed use the NLTK module without explicitly installing the NLTK library.\n",
        ">\n",
        "* NLTKì˜ ê¸°ëŠ¥ì„ ì œëŒ€ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” NLTK Dataë¼ëŠ” ì—¬ëŸ¬ ë°ì´í„°ë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ì„¤ì¹˜í•´ì•¼ í•œë‹¤.\n",
        ">\n",
        "* ì´ë¥¼ ìœ„í•´ì„œ íŒŒì´ì¬ ì½”ë“œ ë‚´ì—ì„œ import nltk ì´í›„ì— nltk.download()ë¼ëŠ” ì½”ë“œë¥¼ ìˆ˜í–‰í•˜ì—¬ ì„¤ì¹˜í•œë‹¤.\n",
        ">\n",
        "* **Reference**\n",
        "  * [wikidocs](https://wikidocs.net/22488)\n"
      ],
      "metadata": {
        "id": "SL1F8WCDKvoN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TPWVgk272SH"
      },
      "outputs": [],
      "source": [
        "!pip install nltk #This step can be skipped since it is pre-installed on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "7dBxHVDoIub9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'brown'> Student's activity** â¤µï¸\n",
        "\n",
        "### Exercise for <font color = 'red'> *importing os module and calling its functions*\n",
        "\n",
        "   -The **os module is a built-in module in Python**, meaning it is available by default in any Python installation. You don't need to install it separately or use any package manager. The os module provides functions for interacting with the operating system, such as accessing files and directories, managing processes, and other system-related tasks. You can import and use the os module in your Python programs without any additional installation steps."
      ],
      "metadata": {
        "id": "hioxpHpfQLjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os                 #Python built-in os module ë¶ˆëŸ¬ ë“¤ì´ê¸°\n",
        "os.mkdir (\"txtfolder\")    #os ëª¨ë“ˆê³¼ mkdir í•¨ìˆ˜ ì‚¬ì´ì— period ìˆìŒ. Check \"txtfolder\" under Files of Colab."
      ],
      "metadata": {
        "id": "8PxL2p05WDin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "text = \"Python programming is a high-level, interpreted programming language known for its simplicity and readability. It emphasizes code readability with its clean syntax, making it easier to write and understand. Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming. It has a vast standard library and a thriving ecosystem of third-party libraries and frameworks, making it suitable for various domains such as web development, data analysis, machine learning, and automation. Python's versatility, ease of use, and extensive community support have contributed to its popularity among developers of all skill levels.\"\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentence = sent_tokenize(text)\n",
        "print('ë¬¸ì¥ í† í°í™”: %s' %sentence)\n"
      ],
      "metadata": {
        "id": "b0VovEVr2dFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ğŸ¹ ğŸ‘€ ğŸ¾ **Lexical-diversity** library is a Python package that provides tools and functions for analyzing the lexical diversity of text.  i) <font color = 'red'>**Type-Token Ratio (TTR)**</font> measures the proportion of unique words (types) in a text compared to the total number of words (tokens). It provides insights into vocabulary richness. ii)  <font color = 'red'>**Moving Standardized Type-Token Ratio (MSTTR)**</font> is a dynamic measure of lexical diversity that takes into account a moving window of text, allowing you to assess diversity over smaller sections of text. iii)  <font color = 'red'>**Moving Average Type-Token Ration (MATTR)**</font> calculates the Type-Token Ratio (TTR) within a sliding window as it moves through the text, and then computes the average of these TTR values over the entire text. The formula for MATTR: MATTR = (1 / N) * âˆ‘(TTR_i).\n",
        "\n",
        "#@markdown ğŸ¹ ğŸ‘€ ğŸ¾ Total number of words / Total number of type\n",
        "\n",
        "!pip install lexical-diversity"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VBD9lDWz0Eoj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}